{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm: Gradient method with Armijo Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\"><img src=\"globalized_newton_method.png\" width=\"700\" height=\"600\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step Size: Armijo Rule\n",
    "- We want to combine the search direction $d^k = - \\nabla f(x^k)$ with step-size $t_k$\n",
    "- The Armijo rule is supposed to ensure a sufficient decrease of the objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_size(self, beta, sigma, x, d, func):\n",
    "    \"\"\"\n",
    "    Armijo's Rule\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    inequality_satisfied = True\n",
    "    while inequality_satisfied:\n",
    "        if func.eval(x + np.power(beta, i) * d) <= func.eval(x) + np.power(beta, i) * sigma * func.gradient(x).dot(\n",
    "                d):\n",
    "            break\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    return np.power(beta, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rosenbrock Function\n",
    "- Introduced by Howard H. Rosenbrock in 1960, used as a performance test problem for optimization problems.\n",
    "- The Rosenbrock function $r: \\mathbb{R}^2 \\rightarrow \\mathbb{R}$ is given by:\n",
    "$$r(x) = 100 (x_2 - x_1^2)^2+ (1 - x_1)^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src.function'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-5c954f8228e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFunction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mRosenbrock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src.function'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from src.function import Function\n",
    "\n",
    "class Rosenbrock(Function):\n",
    "\n",
    "    def eval(self, x):\n",
    "        assert len(x) == 2, '2 dimensional input only.'\n",
    "        return 100 * (x[1] - x[0] ** 2) ** 2 + (1 - x[0]) ** 2\n",
    "\n",
    "    def gradient(self, x):\n",
    "        assert len(x) == 2, '2 dimensional input only.'\n",
    "        return np.array([\n",
    "            2 * (-200 * x[0] * x[1] + 200 * np.power(x[0], 3) - 1 + x[0]),\n",
    "            200 * (x[1] - x[0] ** 2)\n",
    "        ])\n",
    "\n",
    "    def hessian(self, x):\n",
    "        assert len(x) == 2, '2 dimensional input only.'\n",
    "        df_dx1 = -400 * x[1] + 1200 * x[0] ** 2 + 2\n",
    "        df_dx1dx2 = -400 * x[0]\n",
    "        df_dx2dx1 = -400 * x[0]\n",
    "        df_dx2 = 200\n",
    "\n",
    "        return np.array([[df_dx1, df_dx1dx2], [df_dx2dx1, df_dx2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example\n",
    "- The parameters will be the following:\n",
    "$$\\beta := 0.5, \\sigma := 10^{-4}, \\varepsilon := 10^{-4}$$\n",
    "- Start point will be the following:\n",
    "$$x^0 := (-1.2, 1)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 8058\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8058"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_method_rosenbrock(x_0=[-1.2, 1],\n",
    "                           beta=0.5,\n",
    "                           sigma=0.0001,\n",
    "                           epsilon=0.0001,\n",
    "                           f=rosenbrock,\n",
    "                           gradient=rosenbrock_gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
